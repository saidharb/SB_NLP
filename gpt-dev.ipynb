{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90fb94d-f227-4210-8550-b1099942c0f6",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d731f4a-5677-4cca-a0f5-b28e2b5bfdeb",
   "metadata": {},
   "source": [
    "## Explore Tiny Shakespear dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58704bfa-7266-4632-a392-2c8b81dde939",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135a5e26-fe3a-4636-a7d6-8f64563661d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset in characters:  1115393\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ea3a60-e9a3-41bf-b5c3-650a8a46d433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d92eba-2389-4255-9ad9-1747985e3e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Number of unique characters: 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(f\"Number of unique characters: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f0b1e6-1032-48f3-a991-f06b3c6083c8",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca789818-bc76-452f-a0b3-f901734cd972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) } # string to integer\n",
    "itos = { i:ch for i,ch in enumerate(chars) } # integer to string\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bec92e6-f98c-489b-a5cb-7f3fd61f3ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7ce9d-8ded-40c6-8df8-d32e839c6c46",
   "metadata": {},
   "source": [
    "## Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ddc6ea2-f19a-4338-a753-46fa855e3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "015d5fb0-a715-4f5c-a8b3-1060d13d203d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 # or context length\n",
    "train_data[:block_size +1 ]\n",
    "# It is nine characters because then the model can predict the next character 8 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fb6e536-8f0a-48ad-850c-ce29e775f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([18]) the target: 47\n",
      "When the input is tensor([18, 47]) the target: 56\n",
      "When the input is tensor([18, 47, 56]) the target: 57\n",
      "When the input is tensor([18, 47, 56, 57]) the target: 58\n",
      "When the input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When the input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82459e7b-234f-4840-a214-97cefd760e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n",
      "----\n",
      "when input is [53] the target: 59\n",
      "when input is [53, 59] the target: 6\n",
      "when input is [53, 59, 6] the target: 1\n",
      "when input is [53, 59, 6, 1] the target: 58\n",
      "when input is [53, 59, 6, 1, 58] the target: 56\n",
      "when input is [53, 59, 6, 1, 58, 56] the target: 47\n",
      "when input is [53, 59, 6, 1, 58, 56, 47] the target: 40\n",
      "when input is [53, 59, 6, 1, 58, 56, 47, 40] the target: 59\n",
      "when input is [49] the target: 43\n",
      "when input is [49, 43] the target: 43\n",
      "when input is [49, 43, 43] the target: 54\n",
      "when input is [49, 43, 43, 54] the target: 1\n",
      "when input is [49, 43, 43, 54, 1] the target: 47\n",
      "when input is [49, 43, 43, 54, 1, 47] the target: 58\n",
      "when input is [49, 43, 43, 54, 1, 47, 58] the target: 1\n",
      "when input is [49, 43, 43, 54, 1, 47, 58, 1] the target: 58\n",
      "when input is [13] the target: 52\n",
      "when input is [13, 52] the target: 45\n",
      "when input is [13, 52, 45] the target: 43\n",
      "when input is [13, 52, 45, 43] the target: 50\n",
      "when input is [13, 52, 45, 43, 50] the target: 53\n",
      "when input is [13, 52, 45, 43, 50, 53] the target: 8\n",
      "when input is [13, 52, 45, 43, 50, 53, 8] the target: 0\n",
      "when input is [13, 52, 45, 43, 50, 53, 8, 0] the target: 26\n",
      "when input is [1] the target: 39\n",
      "when input is [1, 39] the target: 1\n",
      "when input is [1, 39, 1] the target: 46\n",
      "when input is [1, 39, 1, 46] the target: 53\n",
      "when input is [1, 39, 1, 46, 53] the target: 59\n",
      "when input is [1, 39, 1, 46, 53, 59] the target: 57\n",
      "when input is [1, 39, 1, 46, 53, 59, 57] the target: 43\n",
      "when input is [1, 39, 1, 46, 53, 59, 57, 43] the target: 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e4bab86-b610-4645-954c-2a2883a4018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:] # because no targets -> Loss is None -> logits still have to be permuted -> becomes (B, C)\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # Es gibt ja jetzt für jeden Token eine softmax wahrscheinlichkeit\n",
    "            # torch.multinomial nimmt jetzt zufällig einen dieser Token with respect to their wahrscheinlichkeit\n",
    "            # es ist also am wahrscheinlichsten, dass der Token mit der höchsten probability genommen wird, aber es können auch\n",
    "            # unwahrscheinlichere gewählt werden, was die Ausgabe natürlicher macht\n",
    "            # zum beispiel: \"Die Katze liegt auf dem \" -> Sofa, Bett, Boden -> Greedy würde immer das selbe wählen\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "        \n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "#print(logits.shape) # get the predictions for every \n",
    "#print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61ef29d9-d921-4d41-ae45-5ec3469526c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype = torch.long),max_new_tokens = 100)[0].tolist())) # 0 is the new line character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b503bce1-da9b-4960-8226-e7916b6c55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c6398a7-6224-4ff7-b84f-9451b7f976e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4394798278808594\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23aa2a8d-e78d-4d9e-84aa-3473d451cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I me:\n",
      "\n",
      "\n",
      "my id, s\n",
      "S:\n",
      "\n",
      "Mayo, m.\n",
      "BUTHERO:\n",
      "See cect borenghis.\n",
      "Mory o hisip woow walim,\n",
      "CULBUERDe ce tow hefrwary theds\n",
      "thto y, w t an and:\n",
      "Fr ik's,\n",
      "FF ldot gofrtarrurndse mbashech.\n",
      "Aprixeeave, ok.\n",
      "S al tenowory m:\n",
      "Fithen t cot sut d thaiday, uisitry whesougus sllle igu h w vevoshet olnje ndous; medewil\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype = torch.long),max_new_tokens = 300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629f0bc-143c-4dd5-b97a-d3cbd8197b18",
   "metadata": {},
   "source": [
    "## The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5acb2fe5-8ea4-42c3-b933-f8302bb2beb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bd95fdd4-9417-4d0c-9092-1ccf03a9bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C)) # bow = bag of words (term that people use when you average the words)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #(t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "\n",
    "# BUT its very inefficient -> Marix multiplication helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e8d37e96-b245-431b-a09e-bbe5de6693f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b21db3d-2a3f-4e85-9235-c37fd8b397bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de7e490d-f746-414c-b917-fbb0b1b3696a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 2\n",
    "wei = torch.tril(torch.ones(T, T)) # wei = weights\n",
    "wei = wei/wei.sum(1, keepdim = True)\n",
    "xbow2 = wei @ x # (T,T) @ (B, T, C) -> Pytorch will firs extend the first matrix to a batch dimension\n",
    "# (B, T, T) @ (B, T, C) -> For each batch element --> Result: (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f6b7c49-47e1-48b1-b431-9d8f835612e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 3\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim = -1) # -> produces the averaging matrix\n",
    "xbow3= wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ede7244e-b12a-443b-aeae-cb21cd8a6b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ae944ce2-6b1f-4686-93b8-49bee0249385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "85987f4e-3fc3-4064-8610-e287dad93685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 4: Self-Attention\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Single head of self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias = False)\n",
    "\n",
    "k = key(x) # (B,T,16)\n",
    "q = query(x) # (B,T,16)\n",
    "wei = q @ k.transpose(-2, -1) # do not transpose batch dimension \n",
    "# (B, T, 16) @ (B, 16, T) --> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "# out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04d2b9dc-31fd-4dbe-8d77-e685d5f1e9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
       "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
       "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
       "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
       "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
       "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
       "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "176f38b9-10fb-4a43-99de-540c96dbf0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f23e055-6f9e-4995-9666-940c91319725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "702a4d38-cc93-4024-999e-fd78f1ff6d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ee1229b0-d4cc-4ec2-acb5-bdc6cb8a9e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var() #Scaling keeps variance at one, without scaling softmax converges to one hot encoding when high weights are generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c76a03e4-7c1b-4e5d-80fd-a6065fb4428d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "\n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5db8ff56-8177-4a04-b70f-8db392727d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "af0267ba-7dac-426e-b0e3-e01778ef7986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.5763e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf6142e-df6e-4bdc-a571-9824f462249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "block_size = 32  # Context Length\n",
    "max_iters = 1000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3 #3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64 # needs to be divisible by n_head\n",
    "n_head = 8\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "save_path = 'model_exp.pth'\n",
    "# --------------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "with open('news-commentary-v10.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = { ch:i for i,ch in enumerate(chars) } # string to integer\n",
    "itos = { i:ch for i,ch in enumerate(chars) } # integer to string\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad() # because we are not using backward, makes pytorch faster\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model (X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" One Head of Self-Attention\"\"\"\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim = -1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device)) # (T, C)\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:] # because no targets -> Loss is None -> logits still have to be permuted -> becomes (B, C)\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # Es gibt ja jetzt für jeden Token eine softmax wahrscheinlichkeit\n",
    "            # torch.multinomial nimmt jetzt zufällig einen dieser Token with respect to their wahrscheinlichkeit\n",
    "            # es ist also am wahrscheinlichsten, dass der Token mit der höchsten probability genommen wird, aber es können auch\n",
    "            # unwahrscheinlichere gewählt werden, was die Ausgabe natürlicher macht\n",
    "            # zum beispiel: \"Die Katze liegt auf dem \" -> Sofa, Bett, Boden -> Greedy würde immer das selbe wählen\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8641f72-7cd1-4f6c-80a0-c146b15acec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/97/07fn6f7n48j71zk65dskp3gm0000gn/T/ipykernel_2627/4146350656.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_3.pth'))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BigramLanguageModel:\n\tUnexpected key(s) in state_dict: \"blocks.0.sa.heads.4.tril\", \"blocks.0.sa.heads.4.key.weight\", \"blocks.0.sa.heads.4.query.weight\", \"blocks.0.sa.heads.4.value.weight\", \"blocks.0.sa.heads.5.tril\", \"blocks.0.sa.heads.5.key.weight\", \"blocks.0.sa.heads.5.query.weight\", \"blocks.0.sa.heads.5.value.weight\", \"blocks.0.sa.heads.6.tril\", \"blocks.0.sa.heads.6.key.weight\", \"blocks.0.sa.heads.6.query.weight\", \"blocks.0.sa.heads.6.value.weight\", \"blocks.0.sa.heads.7.tril\", \"blocks.0.sa.heads.7.key.weight\", \"blocks.0.sa.heads.7.query.weight\", \"blocks.0.sa.heads.7.value.weight\", \"blocks.1.sa.heads.4.tril\", \"blocks.1.sa.heads.4.key.weight\", \"blocks.1.sa.heads.4.query.weight\", \"blocks.1.sa.heads.4.value.weight\", \"blocks.1.sa.heads.5.tril\", \"blocks.1.sa.heads.5.key.weight\", \"blocks.1.sa.heads.5.query.weight\", \"blocks.1.sa.heads.5.value.weight\", \"blocks.1.sa.heads.6.tril\", \"blocks.1.sa.heads.6.key.weight\", \"blocks.1.sa.heads.6.query.weight\", \"blocks.1.sa.heads.6.value.weight\", \"blocks.1.sa.heads.7.tril\", \"blocks.1.sa.heads.7.key.weight\", \"blocks.1.sa.heads.7.query.weight\", \"blocks.1.sa.heads.7.value.weight\", \"blocks.2.sa.heads.4.tril\", \"blocks.2.sa.heads.4.key.weight\", \"blocks.2.sa.heads.4.query.weight\", \"blocks.2.sa.heads.4.value.weight\", \"blocks.2.sa.heads.5.tril\", \"blocks.2.sa.heads.5.key.weight\", \"blocks.2.sa.heads.5.query.weight\", \"blocks.2.sa.heads.5.value.weight\", \"blocks.2.sa.heads.6.tril\", \"blocks.2.sa.heads.6.key.weight\", \"blocks.2.sa.heads.6.query.weight\", \"blocks.2.sa.heads.6.value.weight\", \"blocks.2.sa.heads.7.tril\", \"blocks.2.sa.heads.7.key.weight\", \"blocks.2.sa.heads.7.query.weight\", \"blocks.2.sa.heads.7.value.weight\", \"blocks.3.sa.heads.4.tril\", \"blocks.3.sa.heads.4.key.weight\", \"blocks.3.sa.heads.4.query.weight\", \"blocks.3.sa.heads.4.value.weight\", \"blocks.3.sa.heads.5.tril\", \"blocks.3.sa.heads.5.key.weight\", \"blocks.3.sa.heads.5.query.weight\", \"blocks.3.sa.heads.5.value.weight\", \"blocks.3.sa.heads.6.tril\", \"blocks.3.sa.heads.6.key.weight\", \"blocks.3.sa.heads.6.query.weight\", \"blocks.3.sa.heads.6.value.weight\", \"blocks.3.sa.heads.7.tril\", \"blocks.3.sa.heads.7.key.weight\", \"blocks.3.sa.heads.7.query.weight\", \"blocks.3.sa.heads.7.value.weight\", \"blocks.4.sa.heads.4.tril\", \"blocks.4.sa.heads.4.key.weight\", \"blocks.4.sa.heads.4.query.weight\", \"blocks.4.sa.heads.4.value.weight\", \"blocks.4.sa.heads.5.tril\", \"blocks.4.sa.heads.5.key.weight\", \"blocks.4.sa.heads.5.query.weight\", \"blocks.4.sa.heads.5.value.weight\", \"blocks.4.sa.heads.6.tril\", \"blocks.4.sa.heads.6.key.weight\", \"blocks.4.sa.heads.6.query.weight\", \"blocks.4.sa.heads.6.value.weight\", \"blocks.4.sa.heads.7.tril\", \"blocks.4.sa.heads.7.key.weight\", \"blocks.4.sa.heads.7.query.weight\", \"blocks.4.sa.heads.7.value.weight\", \"blocks.5.sa.heads.4.tril\", \"blocks.5.sa.heads.4.key.weight\", \"blocks.5.sa.heads.4.query.weight\", \"blocks.5.sa.heads.4.value.weight\", \"blocks.5.sa.heads.5.tril\", \"blocks.5.sa.heads.5.key.weight\", \"blocks.5.sa.heads.5.query.weight\", \"blocks.5.sa.heads.5.value.weight\", \"blocks.5.sa.heads.6.tril\", \"blocks.5.sa.heads.6.key.weight\", \"blocks.5.sa.heads.6.query.weight\", \"blocks.5.sa.heads.6.value.weight\", \"blocks.5.sa.heads.7.tril\", \"blocks.5.sa.heads.7.key.weight\", \"blocks.5.sa.heads.7.query.weight\", \"blocks.5.sa.heads.7.value.weight\". \n\tsize mismatch for token_embedding_table.weight: copying a param with shape torch.Size([311, 256]) from checkpoint, the shape in current model is torch.Size([26, 32]).\n\tsize mismatch for position_embedding_table.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([16, 32]).\n\tsize mismatch for blocks.0.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.0.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.0.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.0.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.0.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.0.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.0.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.0.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.0.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.1.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.1.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.1.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.1.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.1.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.1.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.1.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.1.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.2.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.2.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.2.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.2.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.2.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.2.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.2.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.2.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.3.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.3.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.3.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.3.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.3.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.3.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.3.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.3.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.4.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.4.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.4.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.4.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.4.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.4.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.4.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.4.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.5.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.5.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.5.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.5.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.5.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.5.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.5.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.5.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for ln_f.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for ln_f.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([311, 256]) from checkpoint, the shape in current model is torch.Size([26, 32]).\n\tsize mismatch for lm_head.bias: copying a param with shape torch.Size([311]) from checkpoint, the shape in current model is torch.Size([26]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = BigramLanguageModel()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model.load_state_dict(torch.load('model.pth'))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m BigramLanguageModel()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_3.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/LocalDocuments/Experiments/SB_NLP/venv_SB_NLP/lib/python3.12/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BigramLanguageModel:\n\tUnexpected key(s) in state_dict: \"blocks.0.sa.heads.4.tril\", \"blocks.0.sa.heads.4.key.weight\", \"blocks.0.sa.heads.4.query.weight\", \"blocks.0.sa.heads.4.value.weight\", \"blocks.0.sa.heads.5.tril\", \"blocks.0.sa.heads.5.key.weight\", \"blocks.0.sa.heads.5.query.weight\", \"blocks.0.sa.heads.5.value.weight\", \"blocks.0.sa.heads.6.tril\", \"blocks.0.sa.heads.6.key.weight\", \"blocks.0.sa.heads.6.query.weight\", \"blocks.0.sa.heads.6.value.weight\", \"blocks.0.sa.heads.7.tril\", \"blocks.0.sa.heads.7.key.weight\", \"blocks.0.sa.heads.7.query.weight\", \"blocks.0.sa.heads.7.value.weight\", \"blocks.1.sa.heads.4.tril\", \"blocks.1.sa.heads.4.key.weight\", \"blocks.1.sa.heads.4.query.weight\", \"blocks.1.sa.heads.4.value.weight\", \"blocks.1.sa.heads.5.tril\", \"blocks.1.sa.heads.5.key.weight\", \"blocks.1.sa.heads.5.query.weight\", \"blocks.1.sa.heads.5.value.weight\", \"blocks.1.sa.heads.6.tril\", \"blocks.1.sa.heads.6.key.weight\", \"blocks.1.sa.heads.6.query.weight\", \"blocks.1.sa.heads.6.value.weight\", \"blocks.1.sa.heads.7.tril\", \"blocks.1.sa.heads.7.key.weight\", \"blocks.1.sa.heads.7.query.weight\", \"blocks.1.sa.heads.7.value.weight\", \"blocks.2.sa.heads.4.tril\", \"blocks.2.sa.heads.4.key.weight\", \"blocks.2.sa.heads.4.query.weight\", \"blocks.2.sa.heads.4.value.weight\", \"blocks.2.sa.heads.5.tril\", \"blocks.2.sa.heads.5.key.weight\", \"blocks.2.sa.heads.5.query.weight\", \"blocks.2.sa.heads.5.value.weight\", \"blocks.2.sa.heads.6.tril\", \"blocks.2.sa.heads.6.key.weight\", \"blocks.2.sa.heads.6.query.weight\", \"blocks.2.sa.heads.6.value.weight\", \"blocks.2.sa.heads.7.tril\", \"blocks.2.sa.heads.7.key.weight\", \"blocks.2.sa.heads.7.query.weight\", \"blocks.2.sa.heads.7.value.weight\", \"blocks.3.sa.heads.4.tril\", \"blocks.3.sa.heads.4.key.weight\", \"blocks.3.sa.heads.4.query.weight\", \"blocks.3.sa.heads.4.value.weight\", \"blocks.3.sa.heads.5.tril\", \"blocks.3.sa.heads.5.key.weight\", \"blocks.3.sa.heads.5.query.weight\", \"blocks.3.sa.heads.5.value.weight\", \"blocks.3.sa.heads.6.tril\", \"blocks.3.sa.heads.6.key.weight\", \"blocks.3.sa.heads.6.query.weight\", \"blocks.3.sa.heads.6.value.weight\", \"blocks.3.sa.heads.7.tril\", \"blocks.3.sa.heads.7.key.weight\", \"blocks.3.sa.heads.7.query.weight\", \"blocks.3.sa.heads.7.value.weight\", \"blocks.4.sa.heads.4.tril\", \"blocks.4.sa.heads.4.key.weight\", \"blocks.4.sa.heads.4.query.weight\", \"blocks.4.sa.heads.4.value.weight\", \"blocks.4.sa.heads.5.tril\", \"blocks.4.sa.heads.5.key.weight\", \"blocks.4.sa.heads.5.query.weight\", \"blocks.4.sa.heads.5.value.weight\", \"blocks.4.sa.heads.6.tril\", \"blocks.4.sa.heads.6.key.weight\", \"blocks.4.sa.heads.6.query.weight\", \"blocks.4.sa.heads.6.value.weight\", \"blocks.4.sa.heads.7.tril\", \"blocks.4.sa.heads.7.key.weight\", \"blocks.4.sa.heads.7.query.weight\", \"blocks.4.sa.heads.7.value.weight\", \"blocks.5.sa.heads.4.tril\", \"blocks.5.sa.heads.4.key.weight\", \"blocks.5.sa.heads.4.query.weight\", \"blocks.5.sa.heads.4.value.weight\", \"blocks.5.sa.heads.5.tril\", \"blocks.5.sa.heads.5.key.weight\", \"blocks.5.sa.heads.5.query.weight\", \"blocks.5.sa.heads.5.value.weight\", \"blocks.5.sa.heads.6.tril\", \"blocks.5.sa.heads.6.key.weight\", \"blocks.5.sa.heads.6.query.weight\", \"blocks.5.sa.heads.6.value.weight\", \"blocks.5.sa.heads.7.tril\", \"blocks.5.sa.heads.7.key.weight\", \"blocks.5.sa.heads.7.query.weight\", \"blocks.5.sa.heads.7.value.weight\". \n\tsize mismatch for token_embedding_table.weight: copying a param with shape torch.Size([311, 256]) from checkpoint, the shape in current model is torch.Size([26, 32]).\n\tsize mismatch for position_embedding_table.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([16, 32]).\n\tsize mismatch for blocks.0.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.0.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.0.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.0.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.0.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.0.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.0.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.0.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.0.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.0.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.0.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.1.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.1.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.1.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.1.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.1.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.1.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.1.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.1.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.1.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.1.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.2.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.2.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.2.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.2.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.2.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.2.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.2.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.2.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.2.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.2.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.3.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.3.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.3.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.3.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.3.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.3.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.3.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.3.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.3.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.3.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.4.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.4.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.4.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.4.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.4.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.4.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.4.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.4.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.4.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.4.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.sa.heads.0.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.5.sa.heads.0.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.0.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.0.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.1.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.5.sa.heads.1.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.1.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.1.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.2.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.5.sa.heads.2.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.2.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.2.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.3.tril: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for blocks.5.sa.heads.3.key.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.3.query.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.heads.3.value.weight: copying a param with shape torch.Size([32, 256]) from checkpoint, the shape in current model is torch.Size([8, 32]).\n\tsize mismatch for blocks.5.sa.proj.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([32, 32]).\n\tsize mismatch for blocks.5.sa.proj.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ffwd.net.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for blocks.5.ffwd.net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for blocks.5.ffwd.net.2.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([32, 128]).\n\tsize mismatch for blocks.5.ffwd.net.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ln1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ln1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ln2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for blocks.5.ln2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for ln_f.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for ln_f.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([311, 256]) from checkpoint, the shape in current model is torch.Size([26, 32]).\n\tsize mismatch for lm_head.bias: copying a param with shape torch.Size([311]) from checkpoint, the shape in current model is torch.Size([26])."
     ]
    }
   ],
   "source": [
    "\n",
    "#model = BigramLanguageModel()\n",
    "#model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "model.load_state_dict(torch.load('model_3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35872e04-8017-47fc-b46a-d6f26dbf5c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32, 65, 61, 74, 67, 77, 59, 64, 61, 70, 1]]\n"
     ]
    }
   ],
   "source": [
    "context = torch.tensor(encode('Eierkuchen '), dtype = torch.long)\n",
    "context = context.unsqueeze(dim = 0)\n",
    "print(context.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f10c8729-a571-4a46-a677-a66eb36dbf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eierkuchen \n"
     ]
    }
   ],
   "source": [
    "print(decode(context.squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "734528ad-6ecf-4786-b58d-f3d709607b52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(decode(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(context, max_new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(context, max_new_tokens = 500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cda2a2e-a15f-4c9a-b776-eac3de6f5a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42852609-dd1b-4735-a3c6-caafa9da282d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdecode\u001b[49m(model\u001b[38;5;241m.\u001b[39mgenerate(context, max_new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decode' is not defined"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(context, max_new_tokens = 500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4be45013-832b-4d32-84f7-ab5edda4bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigram import BigramLanguageModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e59d7c-1d01-4782-b1fd-ac3bb5a4d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 311, 'block_size': 256, 'n_embd': 384, 'n_head': 6, 'n_layer': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/97/07fn6f7n48j71zk65dskp3gm0000gn/T/ipykernel_52332/3792025281.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('model_1.pth', map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model_1.pth', map_location=torch.device('cpu'))\n",
    "config = checkpoint['config']\n",
    "print(config)\n",
    "model = BigramLanguageModel(**config)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42200991-3ee7-4717-a52f-a314251ada36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_config(save_path):\n",
    "    checkpoint = torch.load(save_path, map_location=torch.device('cpu'))\n",
    "    config = checkpoint['config']\n",
    "    model = BigramLanguageModel(**config)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e88cfa7c-e91c-4a0d-9852-9f3ffd221f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/97/07fn6f7n48j71zk65dskp3gm0000gn/T/ipykernel_52332/1855571868.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(save_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "model = load_model_with_config('model_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48620370-dcce-4a71-9c90-e4eee434032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/news-commentary-v10.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = { ch:i for i,ch in enumerate(chars) } # string to integer\n",
    "itos = { i:ch for i,ch in enumerate(chars) } # integer to string\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b07c57b-0ea6-46d7-b818-ef98a8b629ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54, 71, 80, 1, 74, 63, 83, 68, 67, 76, 1, 71, 76, 1, 67, 71, 76, 1, 39, 63, 83, 81, 1]]\n"
     ]
    }
   ],
   "source": [
    "context = torch.tensor(encode('Wir laufen in ein Haus '), dtype = torch.long)\n",
    "context = context.unsqueeze(dim = 0)\n",
    "print(context.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b9fd0e6-16a1-4141-899a-816ba902816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wir laufen in ein Haus dienen die iranische Uneinigkeit verstoßen, einen welttretigen sträubenden Reis allerdings in Frage, ob ein Patrouillen an die Akten in der Leitung gab, die wiederholt mehr besonders gemeinsam dramatisch gebraucht sind.\n",
      "Die Vereinigten Staaten und Zentralregierungen in Glattsindikatoren, insbesondere in Harvard und besondern dafür ist Syriens ideale Systeme, die die immer mehr Chen Olieferung und Gesellschaften zur Überwindung von Arabischen Union im Sinne hinterhergestellt hatten.\n",
      "Als Bürgerrec\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(context, max_new_tokens = 500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b6a342c0-cd9c-4965-bc6d-dbfd0f148031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lyricsgenius import Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "02fe897d-c9c9-404b-99b5-f441156f23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "API = '0X82crAR7oOXruvuM83D4A-dtzSoAY2g5l4dTeUooLmhQhpD2DISXXJDkuTYLx6m'\n",
    "\n",
    "lyrics = []\n",
    "genius = Genius(API)\n",
    "genius.remove_section_headers = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6836128b-5d24-4090-8065-e2ea50567b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by $uicideboy$...\n",
      "\n",
      "Song 1: \"Kill Yourself (Part III)\"\n",
      "Song 2: \"Paris\"\n",
      "Song 3: \"Antarctica\"\n",
      "Song 4: \"$outh $ide $uicide\"\n",
      "Song 5: \"2nd Hand\"\n",
      "Song 6: \"I No Longer Fear the Razor Guarding My Heel\"\n",
      "Song 7: \"Carrollton\"\n",
      "Song 8: \"New Chains, Same Shackles\"\n",
      "Song 9: \"...And to Those I Love, Thanks for Sticking Around\"\n",
      "Song 10: \"O Pana!\"\n",
      "Song 11: \"Memoirs of a Gorilla\"\n",
      "Song 12: \"For the Last Time\"\n",
      "Song 13: \"Kill Yourself (Part IV)\"\n",
      "Song 14: \"Magazine\"\n",
      "Song 15: \"LTE\"\n",
      "Song 16: \"Fuckthepopulation\"\n",
      "Song 17: \"Low Key\"\n",
      "Song 18: \"Champion of Death\"\n",
      "Song 19: \"Mount Sinai\"\n",
      "Song 20: \"All Known $UICIDEBOY$ Alter-Egos and Personas\"\n",
      "Song 21: \"DIEMONDS\"\n",
      "Song 22: \"Now I’m Up to My Neck With Offers\"\n",
      "Song 23: \"122 Days\"\n",
      "Song 24: \"Exodus\"\n",
      "Song 25: \"Do You Believe in God?\"\n",
      "Song 26: \"I No Longer Fear the Razor Guarding My Heel (IV)\"\n",
      "Song 27: \"You’re Now Tuning in to 66.6 FM with DJ Rapture (The Hottest Hour of the Evening)\"\n",
      "Song 28: \"I No Longer Fear the Razor Guarding My Heel (III)\"\n",
      "Song 29: \"Audubon\"\n",
      "Song 30: \"Ultimate $uicide\"\n",
      "Song 31: \"King Tulip\"\n",
      "Song 32: \"10,000 Degrees\"\n",
      "Song 33: \"Either Hated Or Ignored\"\n",
      "Song 34: \"Gloss of Blood\"\n",
      "Song 35: \"Kill Yourself\"\n",
      "Song 36: \"Meet Mr. NICEGUY\"\n",
      "Song 37: \"Kill Your$elf (Part II)\"\n",
      "Song 38: \"Dead Batteries\"\n",
      "Song 39: \"Leave Your Things Behind II\"\n",
      "Song 40: \"Avalon\"\n",
      "Song 41: \"I No Longer Fear the Razor Guarding My Heel (II)\"\n",
      "Song 42: \"I’m Done.\"\n",
      "Song 43: \"That Just Isn’t Empirically Possible\"\n",
      "Song 44: \"Venom\"\n",
      "Song 45: \"Sunshine\"\n",
      "Song 46: \"Hard to Tell\"\n",
      "Song 47: \"Coma\"\n",
      "Song 48: \"Introversion 2.0\"\n",
      "Song 49: \"I Hung Myself for a Persona\"\n",
      "Song 50: \"Nicotine Patches\"\n",
      "Song 51: \"Ugly\"\n",
      "Song 52: \"Eclipse\"\n",
      "Song 53: \"Clouds as Witnesses\"\n",
      "Song 54: \"O’ Lord! I Have My Doubts\"\n",
      "Song 55: \"Putrid Pride\"\n",
      "Song 56: \"Say Cheese and Die\"\n",
      "Song 57: \"Water $uicide\"\n",
      "Song 58: \"All Dogs Go to Heaven\"\n",
      "Song 59: \"Chariot of Fire\"\n",
      "Song 60: \"Matte Black\"\n",
      "Song 61: \"Sold My Soul to Satan Waiting in Line at the Mall\"\n",
      "Song 62: \"Materialism as a Means to an End\"\n",
      "Song 63: \"Leave Me Alone\"\n",
      "Song 64: \"Tulane\"\n",
      "Song 65: \"To Have and Have Not\"\n",
      "Song 66: \"The Nail to the Cross\"\n",
      "Song 67: \"Ugliest\"\n",
      "Song 68: \"Reign in Blood\"\n",
      "Song 69: \"BREAKDALAW2K16\"\n",
      "Song 70: \"Whoa, I’m Woeful\"\n",
      "Song 71: \"I Am the Apocalypse\"\n",
      "Song 72: \"I Want to Believe\"\n",
      "Song 73: \"From the Beginning of Time Until the End of Time\"\n",
      "Song 74: \"Burgundy\"\n",
      "Song 75: \"1000 Blunts\"\n",
      "Song 76: \"Planting the Roots Only to Fall Out the Tree\"\n",
      "Song 77: \"I Miss My Dead Friends\"\n",
      "Song 78: \"Face It\"\n",
      "Song 79: \"T.R.U. (Totally Rotten Underground)\"\n",
      "Song 80: \"Shattered Amethyst\"\n",
      "Song 81: \"​praisethedevil\"\n",
      "Song 82: \"Lucky Me\"\n",
      "Song 83: \"Ocean $ide $uicide\"\n",
      "Song 84: \"Vincent Van Gogh Ain’t Got Shit on Me\"\n",
      "Song 85: \"Fuck\"\n",
      "Song 86: \"Bring Out Your Dead\"\n",
      "Song 87: \"I Think I’m Ian Read\"\n",
      "Song 88: \"Krewe du Vieux (Comedy & Tragedy)\"\n",
      "Song 89: \"The Number You Have Dialed is Not in Service\"\n",
      "Song 90: \"AM/PM\"\n",
      "Song 91: \"Elysian Fields\"\n",
      "Song 92: \"If Self-Destruction was an Olympic Event, I’d be Tonya Harding\"\n",
      "Song 93: \"Handzum $uicide\"\n",
      "Song 94: \"Where’s Your God?\"\n",
      "Song 95: \"Rag Round My Skull\"\n",
      "Song 96: \"NEW PROFILE PIC\"\n",
      "Song 97: \"Rotten and Paralyzed in a Tropical Paradise\"\n",
      "Song 98: \"Uglier\"\n",
      "Song 99: \"Nightmare Choir (I Been Asleep Too Long)\"\n",
      "Song 100: \"WAR TIME ALL THE TIME\"\n",
      "Song 101: \"Failure by Design\"\n",
      "Song 102: \"FUCK the Industry\"\n",
      "Song 103: \"Not Even Ghosts Are This Empty\"\n",
      "Song 104: \"A Death in the Ocean Would Be So Beautiful\"\n",
      "Song 105: \"Cherry P.I.E.\"\n",
      "Song 106: \"Pontiac $unfire\"\n",
      "Song 107: \"A Girl Named Drool and a Pack of Kools\"\n",
      "Song 108: \"What The Fuck Is Happening\"\n",
      "Song 109: \"Long Gone (Save Me from This Hell)\"\n",
      "Song 110: \"Phantom Menace\"\n",
      "Song 111: \"Fuck Your Culture\"\n",
      "Song 112: \"Are You Going to See the Rose in the Vase, or the Dust on the Table?\"\n",
      "Song 113: \"THE_EVIL_THAT_MEN_DO\"\n",
      "Song 114: \"Stop Calling Us Horrorcore\"\n",
      "Song 115: \"Misery in Waking Hours\"\n",
      "Song 116: \"My Flaws Burn Through My Skin Like Demonic Flames from Hell\"\n",
      "Song 117: \"Vices\"\n",
      "Song 118: \"Jeffer Drive\"\n",
      "Song 119: \"Pictures\"\n",
      "Song 120: \"Opal Ring\"\n",
      "Song 121: \"I Wanna Be Romanticized\"\n",
      "Song 122: \"Goosebumps\"\n",
      "Song 123: \"All That Glitters Is Not Gold, But It’s Still Damn Beautiful\"\n",
      "Song 124: \"Fold\"\n",
      "Song 125: \"Fucking Your Culture\"\n",
      "Song 126: \"[whispers indistinctly]\"\n",
      "Song 127: \"Escape from BABYLON\"\n",
      "Song 128: \"#1 Stunna\"\n",
      "Song 129: \"5 Grand at 8 to 1\"\n",
      "Song 130: \"One Last Look at the Damage\"\n",
      "Song 131: \"Paper Bag Mask\"\n",
      "Song 132: \"Genesis\"\n",
      "Song 133: \"Marlboros & White Widow\"\n",
      "Song 134: \"Leave Your Things Behind\"\n",
      "Song 135: \"VIVIVI\"\n",
      "Song 136: \"Harve$t Moon\"\n",
      "Song 137: \"Thorns\"\n",
      "Song 138: \"Temple Spray\"\n",
      "Song 139: \"Bleach\"\n",
      "Song 140: \"Scope Set\"\n",
      "Song 141: \"Kill Yourself V\"\n",
      "Song 142: \"The Thin Grey Line\"\n",
      "Song 143: \"Us Vs. Them\"\n",
      "Song 144: \"NOxygen\"\n",
      "Song 145: \"Aphrodite (The Aquatic Ape Theory)\"\n",
      "Song 146: \"All My Life I’ve Wanted a Chevy\"\n",
      "Song 147: \"It’s Hard to Win When You Always Lose\"\n",
      "Song 148: \"Grayscale\"\n",
      "Song 149: \"Life is but a Stream~\"\n",
      "Song 150: \"The Light at the End of the Tunnel for $9.99 a Month\"\n",
      "Song 151: \"Gloom\"\n",
      "Song 152: \"FUCKALLOFYOU2K18\"\n",
      "Song 153: \"$uicideboy$ Were Better In 2015\"\n",
      "Song 154: \"Bizarro\"\n",
      "Song 155: \"Behold a Pale Horse\"\n",
      "Song 156: \"Magnolia\"\n",
      "Song 157: \"MEGA ZEPH\"\n",
      "Song 158: \"Bloody 98\"\n",
      "Song 159: \"Lamar Avenue\"\n",
      "Song 160: \"Lone Wolf Hysteria\"\n",
      "Song 161: \"275 $uicide\"\n",
      "Song 162: \"$hrimp Poboy\"\n",
      "Song 163: \"In Constant Sorrow\"\n",
      "Song 164: \"Kamehameha (Kamikaze Remix)\"\n",
      "Song 165: \"Converting...\"\n",
      "Song 166: \"That Time We Went to Wal Mart In Memphis To Steal Some Shit Before We Met Up With TA To Shoot His Video\"\n",
      "Song 167: \"Goodbye\"\n",
      "Song 168: \"Dejection\"\n",
      "Song 169: \"Mental Clarity Is a Luxury I Can’t Afford\"\n",
      "Song 170: \"Second Lines Come with Broken Souls\"\n",
      "Song 171: \"Forget It\"\n",
      "Song 172: \"I Ended Up Driving the Camaro Off the Causeway Bridge\"\n",
      "Song 173: \"Smoked Out, Scoped Out\"\n",
      "Song 174: \"Gutting Catfish\"\n",
      "Song 175: \"Prince Tulip\"\n",
      "Song 176: \"Mannequins Are My Best of Friends\"\n",
      "Song 177: \"Evolution (Pretty Good Movie/Pretty Good Theory)\"\n",
      "Song 178: \"Fuck a Hoe\"\n",
      "Song 179: \"Scrape\"\n",
      "Song 180: \"Drag ’Em to the River (Totalitarian Remix)\"\n",
      "Song 181: \"Pump Fake\"\n",
      "Song 182: \"Durango ’95 (A Real Horror Show)\"\n",
      "Song 183: \"The Crescent Moon and the Rising Sun\"\n",
      "Song 184: \"$leep Walk\"\n",
      "Song 185: \"CLYDE (I Hope At Least One Of My Ex-Girlfriends Hears This)\"\n",
      "Song 186: \"WE ENVY NOTHING IN THE WORLD.\"\n",
      "Song 187: \"Can of Worms\"\n",
      "Song 188: \"Degeneration in the Key of A Minor\"\n",
      "Song 189: \"Broke(n)\"\n",
      "Song 190: \"April Mourning\"\n",
      "Song 191: \"Fuck Boy Blood Bath\"\n",
      "Song 192: \"Drugs/Hoes/Money/Etc.\"\n",
      "Song 193: \"Golden Calf\"\n",
      "Song 194: \"Purple Ranger [$ippin’ Donatello with Captain Ginyu Y2K Remix]\"\n",
      "Song 195: \"Resin\"\n",
      "Song 196: \"Eulogy\"\n",
      "Song 197: \"HUNG UP ON THE COME UP\"\n",
      "Song 198: \"Styrofoam\"\n",
      "Song 199: \"Cherish the Dead\"\n",
      "Song 200: \"Withdrawals/Withdrawals\"\n",
      "Song 201: \"Aite, Bet.\"\n",
      "Song 202: \"Lincoln Continental Memorial\"\n",
      "Song 203: \"Limp Wri$t\"\n",
      "Song 204: \"The Sacred\"\n",
      "Song 205: \"La Croix\"\n",
      "Song 206: \"Hair\"\n",
      "Song 207: \"A Little Trauma Can Be Illuminating, And I’m Shining Like The Sun\"\n",
      "Song 208: \"No Matter Which Direction I’m Going In, I Never Chase These Hoes\"\n",
      "Song 209: \"Jon Voight (Live Fast, Die Young)\"\n",
      "Song 210: \"Don’t Give a Fuck ($oul Doubt Remix)\"\n",
      "Song 211: \"Iron Veil\"\n",
      "Song 212: \"Hot Razor\"\n",
      "Song 213: \"Vietnam\"\n",
      "Song 214: \"Transgressions\"\n",
      "Song 215: \"I No Longer Fear the Razor Guarding My Heel (V)\"\n",
      "Song 216: \"Lighting the Flames of My Own Personal Hell\"\n",
      "Song 217: \"Resistance Is Useless\"\n",
      "Song 218: \"Unlucky Me\"\n",
      "Song 219: \"Tempura\"\n",
      "Song 220: \"All of My Problems Always Involve Me\"\n",
      "Song 221: \"Aokigahara\"\n",
      "Song 222: \"Gabapentin Getaway\"\n",
      "Song 223: \"Cerberus\"\n",
      "Song 224: \"Underwater Malibu\"\n",
      "Song 225: \"100 Blunts\"\n",
      "Song 226: \"Novus Ordo Seclorum\"\n",
      "Song 227: \"Smoked Out, Loced Out\"\n",
      "Song 228: \"Romulus\"\n",
      "Song 229: \"Château Gris\"\n",
      "Song 230: \"​nm jc\"\n",
      "Song 231: \"Chevrolet (Pimpalicious Candy Cane Mane ’74 Remix)\"\n",
      "Song 232: \"5 ‘N The Mornin’\"\n",
      "Song 233: \"Prettyleaf\"\n",
      "Song 234: \"Rotten Souls\"\n",
      "Song 235: \"Deep Web\"\n",
      "Song 236: \"Tony Hawk Pro Skater 4\"\n",
      "Song 237: \"Bag$\"\n",
      "Song 238: \"Fake Pontchartrain\"\n",
      "Song 239: \"That’s Very Minimalist of You\"\n",
      "Song 240: \"Finding Shelter In My Larynx\"\n",
      "Song 241: \"Heavily Medicated\"\n",
      "Song 242: \"Maple Syrup\"\n",
      "Song 243: \"​whatwhat\"\n",
      "Song 244: \"Second Coming\"\n",
      "Song 245: \"Black Beard\"\n",
      "Song 246: \"40 Oz. & Sober\"\n",
      "Song 247: \"Ashes of Luxury\"\n",
      "Song 248: \"Gray/Grey\"\n",
      "Song 249: \"I’ll Pay for It (If I Want It)\"\n",
      "Song 250: \"Friday the 13th\"\n",
      "Song 251: \"Mask & da Glock\"\n",
      "Song 252: \"Crucify Me Wearing Tommy\"\n",
      "Song 253: \"Everest\"\n",
      "Song 254: \"Oracle\"\n",
      "Song 255: \"Straw Chairs\"\n",
      "Song 256: \"In Order to Cast a Shadow You Must First Light a Fire\"\n",
      "Song 257: \"Let ’Em Burn\"\n",
      "Song 258: \"Lo-Fi (Kill ’Em All)\"\n",
      "Song 259: \"To Kill a Mockingbird\"\n",
      "Song 260: \"Royal\"\n",
      "Song 261: \"Loot\"\n",
      "Song 262: \"Realism VS Idealism\"\n",
      "Song 263: \"Smoke a Sack\"\n",
      "Song 264: \"Back from the Dead\"\n",
      "Song 265: \"Lemon $lime\"\n",
      "Song 266: \"Lettuce\"\n",
      "Song 267: \"Provolone & Heroin\"\n",
      "Song 268: \"333333 [RARE* ’96 BOOTLEG CA$$ETTE RIP TRE$ $EI$]\"\n",
      "Song 269: \"Gold (’99-2000)\"\n",
      "Song 270: \"Flodgin’\"\n",
      "Song 271: \"$moked Out, Loced Out (Part II)\"\n",
      "Song 272: \"Datura\"\n",
      "Song 273: \"$low Motion Potion\"\n",
      "Song 274: \"St. Bernard\"\n",
      "Song 275: \"Bossier City Kidnap Victims\"\n",
      "Song 276: \"$TORAGE\"\n",
      "Song 277: \"$UICIDEBOY$ Discography\"\n",
      "Song 278: \"Grey Boy$\"\n",
      "Song 279: \"I Will Celebrate for Stepping on Broken Glass and Slipping on Stomach Soaked Floors (Original)\"\n",
      "Song 280: \"7th or St. Tammany\"\n",
      "Song 281: \"Starry 9\"\n",
      "Song 282: \"Gaudy Pack $hawty\"\n",
      "Song 283: \"I No Longer Fear The Razor Guarding My Heel III Official Lyric Book\"\n",
      "Song 284: \"Every Dog Has His Day\"\n",
      "Song 285: \"2ND HAND (Demo)\"\n",
      "Song 286: \"$leepy Hollow (Slopped & Chewed)\"\n",
      "Song 287: \"I Deleted Facebook a Long Time Ago\"\n",
      "Song 288: \"My Scars Are Like Evidence Being Mailed to the Judge\"\n",
      "Song 289: \"Pe$o\"\n",
      "Song 290: \"Trapathy\"\n",
      "Song 291: \"Torcher\"\n",
      "Song 292: \"Didn’t They Give You Percoset?\"\n",
      "Song 293: \"$uicider\"\n",
      "Song 294: \"$ilent Night\"\n",
      "Song 295: \"$aturn $unrise\"\n",
      "Song 296: \"Thieves\"\n",
      "Song 297: \"Spring Season Intro\"\n",
      "Song 298: \"I Will Celebrate for Stepping on Broken Glass and Slipping on Stomach Soaked Floors\"\n",
      "Song 299: \"Psychedelic $uicide\"\n",
      "Song 300: \"Kill Yourself (Leaned Out Remix)\"\n",
      "\"The $UICIDEBOY$ Interview\" is not valid. Skipping.\n",
      "Song 301: \"NUMBING THE PAIN, BECAUSE NERVES ARE OVERRATED\"\n",
      "Song 302: \"100 Blunt$ (DJ Phantazm Remix)\"\n",
      "Song 303: \"Summer Season Intro\"\n",
      "Song 304: \"My Flaws Burn Through My Skin Like Demonic Flames from Hell (Original)\"\n",
      "\"BloodRiversMoon\" is not valid. Skipping.\n",
      "Song 305: \"Fall Season Intro\"\n",
      "Song 306: \"Winter Season Intro\"\n",
      "Song 307: \"Maple Syrup (DJ Poliwhirl Remix)\"\n",
      "Song 308: \"Kill Your$elf (Part II) (Spotify Version)\"\n",
      "Song 309: \"​I H​​UNG MYSELF FOR A PERSONA​///NOW l’M UP TO MY NECK WITH OFFERS\"\n",
      "Song 310: \"Axle Road\"\n",
      "Song 311: \"Fucked Up\"\n",
      "Song 312: \"Resident Evil\"\n",
      "\"YIN/////YANG/////////\" is not valid. Skipping.\n",
      "Song 313: \"Hell (We Livin)\"\n",
      "Song 314: \"$ickk\"\n",
      "\"Unreleased\" is not valid. Skipping.\n",
      "Song 315: \"The Thin Grey Line (Snippet)\"\n",
      "Song 316: \"Untitled\"\n",
      "Song 317: \"Lupin\"\n",
      "\"THE_EVIL_THAT_MEN_DO (Original Version)\" is not valid. Skipping.\n",
      "Song 318: \"My Closet Is a Graveyard\"\n",
      "\"Untitled Song with $uicideboy$*\" is not valid. Skipping.\n",
      "Song 319: \"I Will One Day Learn To Fly into the Stars\"\n",
      "\"Xxplosive sampled track\" is not valid. Skipping.\n",
      "Song 320: \"Dolemite Snippet\"\n",
      "Song 321: \"2nd Hand (Kliptic Remix) [Mixed]\"\n",
      "Song 322: \"If You Were To Get What You Deserve, You Would Know What The Bottom Of A Tire Tasttes Like\"\n",
      "Done. Found 322 songs.\n"
     ]
    }
   ],
   "source": [
    "artist = genius.search_artist(\"$uicideboy$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0fba5630-f93a-483f-8e4e-fa0d933a5b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Lyrics_uicideboy.json already exists. Overwrite?\n",
      "(y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Lyrics_uicideboy.json.\n"
     ]
    }
   ],
   "source": [
    "artist.save_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e857db0-5bfc-4986-94f5-f111ee38e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('Lyrics_uicideboy.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7321232a-38c4-482c-9898-e08e83fa6efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/concatenated_lyrics.txt', 'w', encoding='utf-8') as file:\n",
    "    for i in range(len(data['songs'])):\n",
    "        title = data['songs'][i]['title']\n",
    "        lyrics = data['songs'][i]['lyrics']\n",
    "        start = lyrics.find(title)\n",
    "        end = lyrics.find(\"Embed\")\n",
    "        new_lyrics = lyrics[start:end-3]\n",
    "        remove_phrases = [\"See $uicideboy$ Live\", \"Get tickets\", \"You might also like\", \"might also li\", \"as low as\"]\n",
    "\n",
    "        for phrase in remove_phrases:\n",
    "            new_lyrics = new_lyrics.replace(phrase, \"\")\n",
    "\n",
    "        #sentence_remove = \"See $uicideboy$ LiveGet tickets as low as $82You might also like\"\n",
    "        #new_lyrics = new_lyrics.replace(sentence_remove,\"\")\n",
    "        file.write(new_lyrics + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc1208c-14dd-4842-b57c-847184712b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691866\n"
     ]
    }
   ],
   "source": [
    "with open('concatenated_lyrics.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(len(text))\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = { ch:i for i,ch in enumerate(chars) } # string to integer\n",
    "itos = { i:ch for i,ch in enumerate(chars) } # integer to string\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9229b8-fa2c-4568-94e1-beec52a2e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\xa0', 'á', 'â', 'é', 'ì', 'í', 'ó', 'œ', 'Κ', 'Π', 'ά', 'ί', 'α', 'γ', 'ε', 'η', 'κ', 'λ', 'μ', 'ν', 'ο', 'π', 'ρ', 'ς', 'σ', 'τ', 'υ', 'ό', 'В', 'М', 'С', 'а', 'в', 'г', 'д', 'е', 'и', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ч', 'ь', 'я', 'ἐ', 'ἡ', 'ὁ', 'ὐ', 'ῖ', 'ῶ', '\\u2005', '\\u200b', '–', '—', '‘', '’', '“', '”', '•', '\\u205f', '\\u2060', '↗', '✧', '中', '文', '翻', '译']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "653297ce-fb84-4e65-8c6c-f91c3102707b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "print('\\u205f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98fd2c6a-e817-4286-848a-77bb48114acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.find(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4565b774-8211-448e-bc5f-e6a3b0fa1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29a903c1-63b3-4143-9f54-be35e3112798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_config(save_path):\n",
    "    checkpoint = torch.load(save_path, map_location=torch.device('cpu'))\n",
    "    config = checkpoint['config']\n",
    "    model = BigramLanguageModel(**config)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "655f8e54-13a8-4989-8ff1-c6debb9523ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/97/07fn6f7n48j71zk65dskp3gm0000gn/T/ipykernel_52332/1855571868.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(save_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model_with_config('SB_model_1.pth')\n",
    "model2 = load_model_with_config('SB_model_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886ce863-eede-4901-8d06-70684d8fabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/concatenated_lyrics.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = { ch:i for i,ch in enumerate(chars) } # string to integer\n",
    "itos = { i:ch for i,ch in enumerate(chars) } # integer to string\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a33bf95-163b-4db4-9398-8d91ac22ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50, 61, 1, 75, 69, 71, 67, 61, 1, 57, 1, 37, 1, 62, 77, 68, 68, 1, 71, 62, 1, 50, 61, 61, 60, 1, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "context = torch.tensor(encode('We smoke a J full of Weed \\n '), dtype = torch.long)\n",
    "context = context.unsqueeze(dim = 0)\n",
    "print(context.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0de877e-5115-4b9c-a4c3-f05ebd7916d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We smoke a J full of Weed \n",
      " he smoke a bitch that play hard (Chush it up)\n",
      "Told that bitch, \"Get out my ear,\" she need to chill and— (Hit the blunt)\n",
      "Xanax bars up in my drink, before I pour 'em— (Crush it up)\n",
      "We never fuck with you, fuckboy, don't act like you can— (Hit the blunt)\n",
      "Take that motherfuckin' bat upside your skull and— (Crush it Up)\n",
      "So full of them drugs, I might throw up, I knew I shouldn'ta— (Hit the blunt)\n",
      "[Outro: JGRXXN & Gimisum Family]\n",
      "OxyContin, some Lortabs, crush it up\n",
      "Hit the blunt, hit the blunt, crush it up\n",
      "OxyC\n"
     ]
    }
   ],
   "source": [
    "print(decode(model1.generate(context, max_new_tokens = 512)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94d56b2a-f738-448d-8c69-0e15004b86fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We smoke a J full of Weed \n",
      "  $82[Chorus]\n",
      "Mike a bitch, pick oh, we pick oh\n",
      "Mike a bitch, cered of that motherfucker that motherfuckin' with\n",
      "Creepin' out the smoke a cross traight of spot\n",
      "\n",
      "[Verse 2: YUNG CHRIST]\n",
      "Creepin' out the snakes, buckle dick, count with mud\n",
      "Crucified with the on my mouth\n",
      "Crucified waways, get buckle\n",
      "Keepin' out the crime, keepin' the pistol green live up and therfuckin' cose\n",
      "Crucified with the Files with the Tammy!\"\n",
      "Hear \"Let the Uzi,\" fuck her before whore?\" I need to surrounded at the $uicide to dour\n",
      "Never liq\n"
     ]
    }
   ],
   "source": [
    "print(decode(model2.generate(context, max_new_tokens = 512)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942c026-655c-4df6-9f8e-8391bc299353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_SB_NLP",
   "language": "python",
   "name": "venv_sb_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
